<!DOCTYPE html>
<html lang="ja">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width,initial-scale=1.0">
        <meta name="description" content="これはfujita-createのポートフォリオ(かぶちゃんの説明のページ)です">
        <meta name="author" content="fujita-create">
        <title>Fujita-createのポートフォリオ</title>
        <link rel="stylesheet" href="css/myCSS.css">
        <link rel="stylesheet" href="css/workexplainCSS.css">
    </head>
    <body>
        <div id="loader">
            <canvas id="loading-canvas"></canvas>
            <div id="loading-bar-container">
                <div id="loading-bar"></div>
            </div>
        </div>


        <canvas id="bg"></canvas>
        <header id="headerback">
            <div class="headers">
                <div class="header_left">
                    <h3>Fujita-createポートフォリオ</h3>
                </div>
                <div class="header_right">
                    <a href="index.html">Home</a>
                    <a href="works.html">Works</a>
                </div>
            </div>
        </header>
        <main>
            <hr>
            <div class="Outline">
                <h2>
                    Outline
                </h2>
            </div>
            <div class="outline-content">
                <section>
                    <h3>「Makeup」に関して</h3>
                    <p>
                    Zoomなどのビデオ通話アプリで使える映像加工アプリです<br>
                    Webカメラから取得した映像に対して、目の拡大・口や鼻の変形などの顔加工をリアルタイムに適用し、仮想カメラを通じて配信できます。<br>
                    Googleが開発したMediaPipeを用いることで、顔のランドマーク（目・口・輪郭などの位置）を検出し、映像加工を実装しています。
                    </p>
                    <div>
                        <a href="https://drive.google.com/file/d/1vGekFjUXdUKTV460DoMg2mOAWme6Ucuw/view?usp=drive_link">
                            <img src="static/img/makeup.png" alt="Makeupサムネイル"  class="linkimg">
                        </a>
                        <p id="click">↑ダウンロード(main.exe)</p>
                    </div>

                </section>

                <section>
                    <h3>「使用した技術」</h3>
                    <ul>
                        <li>フロントエンド：Tkinter(GUI)</li>
                        <li>バックエンド：Python</li>
                        <li>外部ライブラリ：numpy, pyvirtualcam, OpenCV, MediaPipe</li>
                        <li>デプロイ：PyInstaller</li>
                        <li>開発環境：Windows11, Python3.10.11, VScode, venv, GithubCopilot, OBSvirtualcam</li>
                        <li>PCデバイス：CPU;Ryzen5 4500 , GPU;GeForce RTX 4060 , RAM;16GB , SSD;1TB </li>
                        <li>WEBカメラ：DEPSTECH DW50PRO 4K Ultra HD 30fps</li>
                    </ul>
                </section>

                <section>
                    <h3>「使用した技術の概要」</h3>
                    <p>Tkinter：Pythonの標準ライブラリ。GUIの作成</p>
                    <p>Python：バックエンド処理を担当</p>
                    <ul>
                        <li>numpy：画像データの数値配列処理、拡大縮小・変形時の演算</li>
                        <li>pyvirtualcam：加工済み映像を仮想カメラとして出力し、Zoom等で使用可能に</li>
                        <li>OpenCV：カメラ映像の取得、画像の前処理・後処理（色変換、ブラーなど）</li>
                        <li>MediaPipe：顔の特徴点（ランドマーク）をリアルタイムで検出、Face Mesh モジュールで468点の顔の部位を認識</li>
                    </ul>
                    <p>PyInstaller：アプリを.exeファイルとして配布可能に</p>
                    <p>OBSvirtualcam：映像をカメラ入力として他アプリに渡すためのもの</p>
                </section>
            </div>
            <div class="Demonstration">
                <h2>
                    Demonstration
                </h2>
                <div class="demo-content">
                <section>
                    <p>Makeupの使い方はこちら</p>
                    <video controls class="demo-video">
                        <source src="" type="video/mp4">
                    </video>
                </section>
                </div>
            </div>
            <div class="Ingenuity">
                <h2>
                    Ingenuity
                </h2>
                <div class="ingenuity-section">
                    <div class="ingenuity-card">
                        <h3>🧠MediaPipeに関して🧠</h3>
                        <p>本アプリでは、Googleが開発したMediaPipeというライブラリを活用し、カメラ映像から顔のランドマーク（目・口・鼻・輪郭などの特徴点）をリアルタイムで検出しています。
                           MediaPipeは、軽量かつ高速な機械学習モデル（主にTensorFlow Lite）とC++ベースの最適化処理によって構成されており、一般的なPC環境でも負荷を抑えて高精度な顔検出が可能です。
                           今回は、特にFace Meshモジュールを使用して、1フレームごとに468点の顔の特徴点を抽出しています。<br>
                           さらに、MediaPipeの出力は比較的安定しており、ユーザーがどの角度を向いても破綻の少ない加工が可能です。
                           そのため、映像加工処理を、現実の顔の動きに追従する形で適用できるようになっています。
                        </p>
                    </div>
                    <div class="ingenuity-card">
                        <h3>📺仮想カメラによる映像連携📺</h3>
                        <p>本アプリでは、顔をリアルタイムで加工した映像を、そのままZoomやGoogle Meetなどのビデオ通話アプリで使用できるよう、仮想カメラ出力の仕組みを導入しています。<br>
                           これには、Pythonライブラリの「pyvirtualcam」を活用しており、アプリ内で生成された映像を“仮想的なWebカメラ”として他のアプリケーションに送信できるようにしています。
                           仮想カメラとは、物理的なカメラを使わずにソフトウェア上で作られた映像を、他のアプリにあたかも通常のカメラ映像のように渡す技術です。<br>
                           この技術は、ライブ配信ツールであるOBS（Open Broadcaster Software）にも搭載されており、OBS仮想カメラが有効化されている環境では、pyvirtualcamによる出力も比較的安定して動作します。
                           ユーザーは、ビデオ通話アプリ上で本アプリの仮想カメラを選択するだけで、リアルタイム加工済みの映像をそのまま映し出すことができ、追加の手間なく理想の見た目で通話に参加することが可能になります。
                           配信ソフトやビデオ会議ツールとの親和性を意識した設計により、柔軟で実用的な映像体験を実現しました。</p>
                    </div>
                    <div class="ingenuity-card">
                        <h3>🖱 GUI操作によるリアルタイム制御 🖱</h3>
                        <p>本アプリでは、Python標準のGUIライブラリであるTkinterを用いて、ユーザーがリアルタイムで映像加工の各種設定を操作できるインターフェースを構築しています。<br>
                           Tkinterはシンプルながら即時応答性の高いUIを構築できるため、リアルタイム映像処理との相性が良く、本アプリにおいても加工のON/OFF切り替えや加工強度の調整を即座に反映できるよう設計されています。<br>
                           ユーザーは、目の拡大、口や鼻の変形、肌のなめらかさといった処理ごとに個別のスライダーやチェックボックスを操作し、映像の変化をその場で確認しながら調整することが可能です。<br>
                           Tkinterのイベント処理機能を通じて、これらの操作はバックエンドの映像処理ロジックとリアルタイムに連携しており、特別な設定や専門知識がなくても、直感的に自分好みの映像加工が行えるようになっています。</p>
                    </div>
                    <div class="ingenuity-card">
                        <h3>✨ 顔の加工処理における工夫 ✨</h3>
                        <p>本アプリでは、MediaPipeによってリアルタイムで検出された顔のランドマーク情報を活用し、映像上の特定部位に対してピンポイントな加工処理を行っています。
                           加工は見た目を変えるだけでなく、自然さとリアルタイム性を両立させることを重視して設計されています。<br>
                           例えば目の拡大処理では、目の輪郭を構成する複数のランドマークをもとに領域を特定し、その部分のみを抽出・拡大してから元の位置に自然な形で合成することで、不自然なゆがみを抑えながら印象的な変化を加えることができます。
                           鼻や口のサイズ調整も同様に、ランドマークに基づく領域指定を行い、その範囲内でのみ画像変形を実施しています。
                           肌のなめらか処理については、顔全体のマスクを生成した上で、選択的にブラー処理を適用することで、画質を落とさずに加工感の少ない補正を実現しています。
                           これにより、リアルな映像体験を損なうことなく、さりげない補正や印象操作が可能になります。<br>
                           加工はすべてリアルタイムで処理されており、ユーザーの表情や動きに即座に追従するため、映像と加工結果の間にズレが生じにくく、自然な使用感を保っています。
                           これらの処理は、各部位のランドマーク情報に依存して動的に適応されるため、あらゆる顔の形や角度に対応可能な柔軟性も備えています。</p>
                    </div>
                    <div class="ingenuity-card">
                        <h3>🔧 今後の課題と改善点 🔧</h3>
                        <p>本アプリは、リアルタイム映像に対して直感的な顔加工を加えられる点において一定の完成度を持っていますが、いくつかの課題も残されています。<br>
                           現時点では、肌のなめらか処理にブラー（ぼかし）処理を用いていますが、処理が単純なため、肌の質感によっては不自然に見えるケースがあります。
                           今後は、肌領域のマスク生成をより精緻化するか、ノイズ除去フィルターやエッジ保持型のスムージングアルゴリズム（例：Bilateral Filterなど）を組み合わせることで、より自然な補正表現の実現を目指しています。<br>
                           また、現在は目や口、鼻といった顔の一部に対する変形機能が中心となっていますが、顔全体の印象に影響する「顎のラインを調整する機能」は未実装です。
                           Face Meshのランドマークを活用すれば顎の輪郭も動的に認識できるため、小顔補正やフェイスラインの調整など、さらなる見た目の印象操作を取り入れていく予定です。
                           GUIに関しても、現在は機能性を重視した簡素な設計となっており、初めて使用するユーザーにとってはやや無機質な印象を与える可能性があります。
                           今後は色彩設計やアイコン導入などのUI/UX改善を進め、視覚的にも楽しめるアプリ体験を提供できるようにしていきたいと考えています。</p>
                    </div>
                </div>
            </div>
        </main>

    <script type="module" src="Three.js/SpaceBackground.js"></script>
    <script type="module" src="Three.js/earthLoader.js"></script>
    </body>
</html>